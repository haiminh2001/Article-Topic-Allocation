{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":31286,"status":"ok","timestamp":1637843822238,"user":{"displayName":"Hải Minh Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYI7h2MkYpsPBPsQyrNDaGhPG2UCkk1vrAK69kqA=s64","userId":"16371132940967469863"},"user_tz":-420},"id":"7CINd0PqKhS-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading learnt vocab\n"]}],"source":["#load vocab builder\n","from data_module import VocabBuilder\n","#hoc cai vocab\n","vocab_builder = VocabBuilder()\n","print(len(vocab_builder.vocab))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRlgk4KmICMu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: All of learnt vocabulary will be erased: y/n\n","Erased!\n"]}],"source":["# vocab_builder.erase()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n"]}],"source":["from data_module import DataHolder\n","data_holder = DataHolder()\n","# vocab_builder.fit(data_holder.texts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n"]},{"name":"stdout","output_type":"stream","text":["Setting up model...\n"]}],"source":["from model_module import WordEmbedder\n","#train wordembedder \n","we = WordEmbedder(load_embedder= False, max_vocab_length= 2000, vocab_builder= vocab_builder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["One hot encoding...\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/8456 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[['Thí_điểm', 'thu', 'phí', 'không', 'dừng', 'trên', 'toàn', 'cao_tốc', 'Hà_Nội', '-', 'Hải_Phòng', 'Cao_tốc', 'Hà_Nội', '-', 'Hải_Phòng', 'sẽ', 'thí_điểm', 'thu', 'phí', 'không', 'dừng', 'từ', 'tháng', '4', 'năm', 'sau', ',', 'không', 'còn', 'làn', 'thu', 'phí', 'một', 'dừng', 'như', 'hiện_nay', '.'], ['Chiều', '23/11', ',', 'ông', 'Nguyễn_Mạnh_Thắng', ',', 'Phó', 'tổng_cục', 'trưởng', 'Đường_bộ', 'Việt_Nam', ',', 'cho', 'biết', 'cơ_quan', 'này', 'đã', 'thống_nhất', 'với', 'chủ', 'đầu_tư', 'tuyến', 'cao_tốc', 'Hà_Nội', '-', 'Hải_Phòng', 'thu', 'phí', 'hoàn_toàn', 'bằng', 'hệ_thống', 'tự_động', 'không', 'dừng', '(', 'ETC', ')', '.'], ['Chỉ', 'có', 'phương_tiện', 'dán', 'thẻ', 'và', 'nạp', 'tiền', 'sử_dụng', 'dịch_vụ', 'mới', 'được', 'đi', 'trên', 'tuyến', '.'], ['Tổng_cục', 'Đường_bộ', 'Việt_Nam', 'sẽ', 'tuyên_truyền', 'trong', '3', 'tháng', '(', 'từ', 'nay', 'đến', 'hết', 'quý', 'I', '/', '2022', ')', 'để', 'chủ', 'xe', 'nắm', 'được', 'thông_tin', 'và', 'chuẩn_bị', 'dán', 'thẻ', 'ETC', '.'], ['Sau', 'thời_gian', 'này', ',', 'xe', 'không', 'đủ', 'điều_kiện', 'thu', 'phí', 'không', 'dừng', 'sẽ', 'không', 'được', 'chạy', 'trên', 'cao_tốc', 'Hà_Nội', '-', 'Hải_Phòng', '.'], ['Chủ', 'xe', 'có_thể', 'chuyển', 'sang', 'quốc_lộ', '5', 'và', 'vẫn', 'sử_dụng', 'vé', 'lượt', 'khi', 'qua', 'trạm', 'thu', 'phí', '.']]\n","<class 'list'>\n","['Thí_điểm', 'thu', 'phí', 'không', 'dừng', 'trên', 'toàn', 'cao_tốc', 'Hà_Nội', '-', 'Hải_Phòng', 'Cao_tốc', 'Hà_Nội', '-', 'Hải_Phòng', 'sẽ', 'thí_điểm', 'thu', 'phí', 'không', 'dừng', 'từ', 'tháng', '4', 'năm', 'sau', ',', 'không', 'còn', 'làn', 'thu', 'phí', 'một', 'dừng', 'như', 'hiện_nay', '.']\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"UnboundLocalError","evalue":"local variable 'one_hots' referenced before assignment","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15496/438659873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata_holder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\haimi\\OneDrive\\Documents\\GitHub\\Article Topic Allocation\\model_module\\WordEmbedding.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, texts, epochs, batch_size, num_workers, pin_memory)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m#prepare data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;31m#fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         self.trainer.fit(\n","\u001b[1;32mc:\\Users\\haimi\\OneDrive\\Documents\\GitHub\\Article Topic Allocation\\model_module\\WordEmbedding.py\u001b[0m in \u001b[0;36msetup_data\u001b[1;34m(self, texts, batch_size, num_workers, pin_memory, inference)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_ends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text_ends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_builder\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_builder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_vocab_length\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_vocab_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\haimi\\OneDrive\\Documents\\GitHub\\Article Topic Allocation\\data_module\\DataModule.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, texts, vocab_builder, max_vocab_length, window_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_vocab_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\haimi\\OneDrive\\Documents\\GitHub\\Article Topic Allocation\\data_module\\DataModule.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mone_hots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mone_hots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'one_hots' referenced before assignment"]}],"source":["we.fit(texts= data_holder.texts, epochs= 20, batch_size= 256, num_workers= 2)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMzZSZ6kYgdpbUOf84/5JVQ","collapsed_sections":[],"mount_file_id":"1vXJ8uWEkYjvJRw5CRnvBJ3vfm4hgIJg2","name":"Article Topic Allocation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
